{
 "cells": [
  {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GPT4o assistant Text description"
      ]
    },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install\n",
    "!pip install openai==1.14.3 --quiet\n",
    "!pip install -q openai>=1.0.0 transformers pandas openpyxl pillow bert_score\n",
    "\n",
    "#Import Library\n",
    "import os, glob, torch, pandas as pd\n",
    "from PIL import Image, ImageFile\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "from bert_score import score as bertscore\n",
    "from openai import OpenAI, OpenAIError\n",
    "\n",
    "#Setting\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "client = OpenAI(api_key=\"YOUR_API_KEY\")  # ← 반드시 유효한 GPT-4o 키로 교체\n",
    "\n",
    "def check_api_key_validity(api_key: str) -> bool:\n",
    "    try:\n",
    "        client = OpenAI(api_key=api_key)\n",
    "        _ = client.models.list()\n",
    "        print(\"API 키가 유효합니다.\")\n",
    "        return True\n",
    "    except OpenAIError as e:\n",
    "        print(\"API 키 오류 발생:\")\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "#API Key\n",
    "api_key = \"YOUR_API_KEY\"\n",
    "check_api_key_validity(api_key)\n",
    "\n",
    "#Import BLIP-2\n",
    "processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-flan-t5-xl\")\n",
    "blip_model = Blip2ForConditionalGeneration.from_pretrained(\n",
    "    \"Salesforce/blip2-flan-t5-xl\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "#Upload Data\n",
    "df = pd.read_excel(\"/content2/fewshot_data.xlsx\")\n",
    "answer_cols = [col for col in df.columns if str(col).lower().startswith(\"answer\")]\n",
    "image_paths = sorted(glob.glob(\"/content2/*.[jpJP][pnNP]*[gG]\"))\n",
    "\n",
    "#Definition\n",
    "def generate_caption(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, text=\"Describe this image in detail.\", return_tensors=\"pt\").to(\"cuda\", torch.float16)\n",
    "    output = blip_model.generate(**inputs)\n",
    "    return processor.batch_decode(output, skip_special_tokens=True)[0].strip()\n",
    "\n",
    "#Few-shot Prompting\n",
    "def build_fewshot_prompt(example_qas, new_caption):\n",
    "    prompt = \"\"\n",
    "    for q, a in example_qas:\n",
    "        prompt += f\"질문: {q}\\n답변: {a}\\n\\n\"\n",
    "    prompt += f\"질문: {new_caption}\\n답변:\"\n",
    "    return prompt\n",
    "\n",
    "#GPT-4o\n",
    "def generate_gpt4o_response(prompt):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=512\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"[ERROR] {e}\"\n",
    "\n",
    "#Generate description\n",
    "captions, prompts, responses, answer_lists = [], [], [], []\n",
    "\n",
    "for idx, image_path in enumerate(image_paths):\n",
    "    try:\n",
    "        caption = generate_caption(image_path)\n",
    "        row_answers = [df.loc[idx, col] for col in answer_cols if pd.notna(df.loc[idx, col]) and str(df.loc[idx, col]).strip()]\n",
    "        fewshot_qas = [(caption, ans) for ans in row_answers[:3]] if row_answers else []\n",
    "\n",
    "        if not fewshot_qas:\n",
    "            print(f\"예시 없음 → {os.path.basename(image_path)} 생략\")\n",
    "            continue\n",
    "\n",
    "        prompt = build_fewshot_prompt(fewshot_qas[:-1], caption)\n",
    "        answer_lists.append(row_answers)\n",
    "        prompts.append(prompt)\n",
    "        captions.append(caption)\n",
    "        response = generate_gpt4o_response(prompt)\n",
    "        responses.append(response)\n",
    "        print(f\"{os.path.basename(image_path)} 완료\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{os.path.basename(image_path)} 실패: {e}\")\n",
    "\n",
    "#BERTScore\n",
    "best_scores = {\n",
    "    \"precision\": [], \"recall\": [], \"f1\": [], \"matched_answer\": []\n",
    "}\n",
    "\n",
    "for refs, cand in zip(answer_lists, responses):\n",
    "    if not refs or \"[ERROR]\" in cand:\n",
    "        best_scores[\"precision\"].append(0.0)\n",
    "        best_scores[\"recall\"].append(0.0)\n",
    "        best_scores[\"f1\"].append(0.0)\n",
    "        best_scores[\"matched_answer\"].append(\"[EMPTY]\")\n",
    "    else:\n",
    "        P, R, F1 = bertscore(cands=[cand]*len(refs), refs=refs, lang=\"ko\", verbose=False)\n",
    "        idx = F1.argmax().item()\n",
    "        best_scores[\"precision\"].append(P[idx].item())\n",
    "        best_scores[\"recall\"].append(R[idx].item())\n",
    "        best_scores[\"f1\"].append(F1[idx].item())\n",
    "        best_scores[\"matched_answer\"].append(refs[idx])\n",
    "\n",
    "#Display as DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    \"image\": [os.path.basename(p) for p in image_paths[:len(responses)]],\n",
    "    \"caption\": captions,\n",
    "    \"fewshot_prompt\": prompts,\n",
    "    \"gpt4o_response\": responses,\n",
    "    \"matched_answer\": best_scores[\"matched_answer\"],\n",
    "    \"bert_precision\": best_scores[\"precision\"],\n",
    "    \"bert_recall\": best_scores[\"recall\"],\n",
    "    \"bert_f1\": best_scores[\"f1\"]\n",
    "})\n",
    "results_df.to_excel(\"/content2/llm_result_gpt4o_fewshot_blip2.xlsx\", index=False)\n",
    "print(\"files.download: /content2/llm_result_gpt4o_fewshot_blip2.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
