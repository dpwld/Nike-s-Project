{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# STEP 0. 필요한 패키지 재설치 (openai 구버전 포함)\n",
        "!pip uninstall -y openai -q\n",
        "!pip install openai==0.28 -q\n",
        "!pip install -q transformers pandas openpyxl pillow bert_score"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1. 라이브러리 임포트\n",
        "import os, glob\n",
        "import openai\n",
        "import torch\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageFile\n",
        "from transformers import InstructBlipProcessor, InstructBlipForConditionalGeneration\n",
        "from bert_score import score as bertscore"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2. 이미지 로딩 오류 허용\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3. OpenAI API 키 설정\n",
        "openai.api_key = \"sk-*****\"  # ← 여기에 본인의 OpenAI API 키 입력"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4. BLIP-2 모델 로딩\n",
        "blip_processor = InstructBlipProcessor.from_pretrained(\"Salesforce/instructblip-vicuna-7b\")\n",
        "blip_model = InstructBlipForConditionalGeneration.from_pretrained(\n",
        "    \"Salesforce/instructblip-vicuna-7b\", torch_dtype=torch.float16, device_map=\"auto\"\n",
        ")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 5. 이미지 및 정답 엑셀 로딩\n",
        "excel_path = \"/content/fewshot_data.xlsx\"\n",
        "df = pd.read_excel(excel_path)\n",
        "answer_cols = [\"answer_1\"]\n",
        "image_paths = sorted(glob.glob(\"/content/*.[jpJP][pnNP]*[gG]\"))"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 6. 보조 함수\n",
        "def generate_caption(image_path):\n",
        "    image = Image.open(image_path).convert(\"RGB\").resize((384, 384))\n",
        "    prompt = \"You are a helpful assistant. Describe this image in detail.\"\n",
        "    inputs = blip_processor(images=image, text=prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    output = blip_model.generate(**inputs)\n",
        "    caption = blip_processor.batch_decode(output, skip_special_tokens=True)[0].strip()\n",
        "    return caption.replace(prompt, \"\").strip()\n",
        "\n",
        "def generate_gpt4_response(prompt):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.7,\n",
        "        max_tokens=150\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"].strip()"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 7. 이미지별 응답 생성\n",
        "captions, gpt_responses, answer_lists = [], [], []\n",
        "\n",
        "for idx, image_path in enumerate(image_paths):\n",
        "    try:\n",
        "        caption = generate_caption(image_path)\n",
        "        captions.append(caption)\n",
        "\n",
        "        prompt = f\"{caption}\\nAnswer:\"\n",
        "        response = generate_gpt4_response(prompt)\n",
        "        gpt_responses.append(response)\n",
        "\n",
        "        row_answers = [df.loc[idx, col] for col in answer_cols if pd.notna(df.loc[idx, col]) and str(df.loc[idx, col]).strip()]\n",
        "        answer_lists.append(row_answers if row_answers else [\"[EMPTY]\"])\n",
        "\n",
        "        print(f\"✅ {os.path.basename(image_path)} 완료\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ {os.path.basename(image_path)} 실패: {e}\")\n",
        "        captions.append(\"[ERROR]\")\n",
        "        gpt_responses.append(f\"[ERROR] {e}\")\n",
        "        answer_lists.append([\"[EMPTY]\"])"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 8. BERTScore 평가\n",
        "best_scores = {\n",
        "    \"precision\": [], \"recall\": [], \"f1\": [], \"matched_answer\": []\n",
        "}\n",
        "\n",
        "for refs, cand in zip(answer_lists, gpt_responses):\n",
        "    if not refs or cand.strip() == \"\":\n",
        "        best_scores[\"precision\"].append(0.0)\n",
        "        best_scores[\"recall\"].append(0.0)\n",
        "        best_scores[\"f1\"].append(0.0)\n",
        "        best_scores[\"matched_answer\"].append(\"[EMPTY]\")\n",
        "        continue\n",
        "\n",
        "    P, R, F1 = bertscore(cands=[cand]*len(refs), refs=refs, lang=\"ko\", verbose=False)\n",
        "    best_idx = F1.argmax().item()\n",
        "    best_scores[\"precision\"].append(P[best_idx].item())\n",
        "    best_scores[\"recall\"].append(R[best_idx].item())\n",
        "    best_scores[\"f1\"].append(F1[best_idx].item())\n",
        "    best_scores[\"matched_answer\"].append(refs[best_idx])"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 9. 결과 저장\n",
        "results_df = pd.DataFrame({\n",
        "    \"image\": [os.path.basename(p) for p in image_paths],\n",
        "    \"caption\": captions,\n",
        "    \"gpt4_response\": gpt_responses,\n",
        "    \"matched_answer\": best_scores[\"matched_answer\"],\n",
        "    \"bert_precision\": best_scores[\"precision\"],\n",
        "    \"bert_recall\": best_scores[\"recall\"],\n",
        "    \"bert_f1\": best_scores[\"f1\"]\n",
        "})\n",
        "results_df.to_excel(\"/content/llm_result_gpt4.xlsx\", index=False)\n",
        "print(\"✅ 저장 완료: /content/llm_result_gpt4.xlsx\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}
